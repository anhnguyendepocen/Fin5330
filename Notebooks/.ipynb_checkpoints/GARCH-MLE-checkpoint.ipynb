{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Brough Lecture Notes: GARCH Models - Estimation via MLE__\n",
    "\n",
    "<br>\n",
    "\n",
    "Finance 5330: Financial Econometrics <br>\n",
    "Tyler J. Brough <br>\n",
    "Last Updated: March 28, 2019 <br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "These notes are based in part on the excellent monograph [Introduction to Python for Econometrics, Statistics, and Data Analysis](https://www.kevinsheppard.com/images/b/b3/Python_introduction-2016.pdf) by the econometrician Kevin Sheppard of Oxford Univeristy. Many thanks to Dr. Sheppard for making his lecture material publically available. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating GARCH Models\n",
    "\n",
    "The standard procedure to fit GARCH models to historical returns time series data is to implement a numerical _maximum likelihood estimation_ (MLE) method. \n",
    "\n",
    "<br>\n",
    "\n",
    "__NB:__ though [Bayesian](https://www.springer.com/us/book/9783540786566) methods have been shown to be superior!\n",
    "\n",
    "<br>\n",
    "\n",
    "The typical setup is as follows: \n",
    "\n",
    "* Continuously compounded returns are assumed to have a conditionally normal distribution $N(0, \\sigma_{t})$\n",
    "\n",
    "* We can estimate the GARCH parameter weights via a numerical optimization routine such as Nelder-Mead or Newton-Raphson.\n",
    "\n",
    "* That is, the numerical routine searches for the parameter values that maximizes the value of the likelihood function.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the normality assumption the probility density of $\\epsilon_{t}$, conditional on $\\sigma_{t}$, is \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "f(\\epsilon | \\sigma_{t}) = \\frac{1}{\\sqrt{2\\pi \\sigma_{t}}} e^{-0.5  \\frac{\\epsilon_{t}^{2}}{\\sigma_{t}}}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Since the $\\epsilon_{t}$ are conditionally independent, the probability of observing the actual returns that are observed is  the product of the probabilities, this is given by the likelihood function:\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\prod\\limits_{t=1}^{T} f(\\epsilon_{t} | \\sigma_{t}) = \\prod\\limits_{t=1}^{T} \\left( \\frac{1}{\\sqrt{2\\pi \\sigma_{t}}} e^{-0.5  \\frac{\\epsilon_{t}^{2}}{\\sigma_{t}}} \\right)\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "For the GARCH(1,1) model, $\\sigma_{t}$ is a function of $\\omega$, $\\alpha$, and $\\beta$. The MLE will select values for these parameters $\\hat{\\omega}$, $\\hat{\\alpha}$, and $\\hat{\\beta}$ - that maximize the value of the probability of observing the returns we actually historically did observe. \n",
    "\n",
    "<br>\n",
    "\n",
    "Typically, it is easiest to maximize the value of the log-likelihood function as follows: \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\sum\\limits_{t=1}^{T} \\left[ -0.5 \\ln{(\\sigma_{t})} - 0.5 \\frac{\\epsilon_{t}^{2}}{\\sigma_{t}}\\right]\n",
    "$$\n",
    "\n",
    "We can omit the term $-0.5 \\ln{(2 \\pi)}$ since it does not affect the solution. Though sometimes it is left in. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement this MLE estimation in Python by utilizing the [optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html) module in [Scipy](https://docs.scipy.org/doc/scipy/reference/index.html), which contains a host of numerical optimization routines. \n",
    "\n",
    "<br>\n",
    "\n",
    "First, we need to define a function to implement the log-likelihood function.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "import seaborn\n",
    "from numpy import size, log, exp, pi, sum, diff, array, zeros, diag, mat, asarray, sqrt, copy\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch_likelihood(params, data, sigma2, out=None):\n",
    "    mu = params[0]\n",
    "    omega = params[1]\n",
    "    alpha = params[2]\n",
    "    beta = params[3]\n",
    "    \n",
    "    T = size(data, 0)\n",
    "    eps = data - mu\n",
    "    \n",
    "    for t in range(1, T):\n",
    "        sigma2[t] = omega + alpha * eps[t-1]**2 + beta * sigma2[t-1]\n",
    "        \n",
    "    lls = 0.5 * (log(2 * pi) + log(sigma2) + eps**2/sigma2)\n",
    "    ll = sum(lls)\n",
    "    \n",
    "    if out is None:\n",
    "        results = ll\n",
    "    else:\n",
    "        results = (ll, lls, copy(sigma2))\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We should begin with data simulated from the model as a first-run test case. So, let's import the simulation code.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set GARCH parameters (these might come from an estimated model)\n",
    "mu = log(1.15) / 252\n",
    "w = 10.0**-6\n",
    "a = 0.085\n",
    "b = 0.905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15874507866387536"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(w / (1.0 - a - b)) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_garch(parameters, numObs):\n",
    "    \n",
    "    ## extract the parameter values\n",
    "    mu = parameters[0]\n",
    "    w = parameters[1]\n",
    "    a = parameters[2]\n",
    "    b = parameters[3]\n",
    "    \n",
    "    ## initialize arrays for storage\n",
    "    z = np.random.normal(size=(numObs + 1))\n",
    "    q = zeros((numObs + 1))\n",
    "    r = zeros((numObs + 1))\n",
    "    \n",
    "    ## fix initial values \n",
    "    q[0] = w / (1.0 - a - b)\n",
    "    r[0] = mu + z[0] * sqrt(q[0])\n",
    "    e = (r[0] - mu) \n",
    "    \n",
    "    ## run the main simulation loop\n",
    "    for t in range(1, numObs + 1):\n",
    "        q[t] = w + a * (e * e) + b * q[t-1]\n",
    "        r[t] = mu + z[t] * sqrt(q[t])\n",
    "        e = (r[t] - mu) \n",
    "        \n",
    "    ## return a tuple with both returns and conditional variances\n",
    "    return (r, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of trading days per year\n",
    "numObs = 2500\n",
    "\n",
    "## daily continuously compounded rate of return correpsonding to 15% annual\n",
    "#mu = log(1.15) / 252\n",
    "#mu = 0.0\n",
    "\n",
    "## drift and GARCH(1,1) parameters in an array\n",
    "params = array([mu, w, a, b])\n",
    "\n",
    "## run the simulation\n",
    "r, s = simulate_garch(params, numObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Okay, now we will set up the estimation of the model on this simulated data. The goal is to see if the numerical search routine embedded in the maximum likelihood estimation\n",
    "can recapture the preset parameter weights given above. \n",
    "\n",
    "<br>\n",
    "\n",
    "It is important to test our software with a known scenario like this before we take the model to real-world data first as a sanity check. Otherwise we could end up chasing our tails for hours and hours without effect. \n",
    "\n",
    "<br>\n",
    "\n",
    "The numerical algorithm requires good starting values as initial conditions for the search to begin. Here we will follow Sheppard. (Notice that this feels \"prior\" like, as in the Bayesian sense) A more data-based way to do this is to use some kind of grid search to find values that have \"small\" log-likelihood values. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005889303527271982"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begVals = array([r.mean(), r.var() * .01, .09, .90])\n",
    "begVals = array([mu, w, a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "finfo = np.finfo(np.float64)\n",
    "bounds = [(-10 * r.mean(), 10 * r.mean()), (finfo.eps, 2 * r.var()), (0.0, 1.0), (0.0, 1.0)]\n",
    "#results = opt.minimize(fun=garch_likelihood, x0=begVals, args=(r,s), method='L-BFGS-B', bounds=bounds)\n",
    "#results = opt.minimize(fun=garch_likelihood, x0=begVals, args=(r,s), method='Nelder-Mead')\n",
    "results = opt.minimize(fun=garch_likelihood, x0=begVals, args=(r,s), method='BFGS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: -8164.241691969553\n",
       " hess_inv: array([[ 2.61645762e-08,  9.40425497e-13, -1.43341977e-08,\n",
       "        -5.20680878e-09],\n",
       "       [ 9.40425497e-13,  1.52534302e-13, -7.53473757e-09,\n",
       "         3.76315979e-09],\n",
       "       [-1.43341977e-08, -7.53473757e-09,  4.80530085e-04,\n",
       "        -2.46500899e-04],\n",
       "       [-5.20680878e-09,  3.76315979e-09, -2.46500899e-04,\n",
       "         1.27968430e-04]])\n",
       "      jac: array([6.10351562e-05, 3.99658203e-01, 6.10351562e-05, 6.10351562e-05])\n",
       "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "     nfev: 353\n",
       "      nit: 11\n",
       "     njev: 57\n",
       "   status: 2\n",
       "  success: False\n",
       "        x: array([6.17962579e-04, 1.09401589e-06, 8.84289107e-02, 9.02360284e-01])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated mean return is:  0.00061796 vs  0.00055461\n",
      "The estimated omega value is:  0.00000109 vs  0.00000100\n",
      "The estimated alpha value is:  0.08842891 vs  0.08500000\n",
      "The estimated beta values is:  0.90236028 vs  0.90500000\n"
     ]
    }
   ],
   "source": [
    "vals = results['x']\n",
    "print(f\"The estimated mean return is: {vals[0] : 0.8f} vs {mu : 0.8f}\")\n",
    "print(f\"The estimated omega value is: {vals[1] : 0.8f} vs {w : 0.8f}\")\n",
    "print(f\"The estimated alpha value is: {vals[2] : 0.8f} vs {a : 0.08f}\")\n",
    "print(f\"The estimated beta values is: {vals[3] : 0.8f} vs {b : 0.08f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16500859496922918"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.std(ddof=1) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "___So much depends upon those initial guesses!___\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GARCH Estimation on IBM Returns from January 1999 to 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garch_constraints(params, data, sigma2, out=None):\n",
    "    omega = params[1]\n",
    "    alpha = params[2]\n",
    "    beta = params[3]\n",
    "    \n",
    "    return array([[omega], [alpha], [beta], [1.0 - alpha - beta]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm = pd.read_csv(\"./data/IBM-1999-2003.csv\", parse_dates=True, index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>CFACPR</th>\n",
       "      <th>RETX</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-01-04</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>183.0000</td>\n",
       "      <td>-0.007458</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.007458</td>\n",
       "      <td>-0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-05</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>189.6250</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036202</td>\n",
       "      <td>0.013582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-06</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>188.7500</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-07</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>190.1875</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>-0.002051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-01-08</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>187.5625</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.004221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PERMNO TICKER                            COMNAM  PERMCO       PRC  \\\n",
       "date                                                                            \n",
       "1999-01-04   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  183.0000   \n",
       "1999-01-05   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  189.6250   \n",
       "1999-01-06   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  188.7500   \n",
       "1999-01-07   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  190.1875   \n",
       "1999-01-08   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  187.5625   \n",
       "\n",
       "                 RET  CFACPR      RETX    sprtrn  \n",
       "date                                              \n",
       "1999-01-04 -0.007458       2 -0.007458 -0.000919  \n",
       "1999-01-05  0.036202       2  0.036202  0.013582  \n",
       "1999-01-06 -0.004614       2 -0.004614  0.022140  \n",
       "1999-01-07  0.007616       2  0.007616 -0.002051  \n",
       "1999-01-08 -0.013802       2 -0.013802  0.004221  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>CFACPR</th>\n",
       "      <th>RETX</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-12-24</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>92.27</td>\n",
       "      <td>-0.005604</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005604</td>\n",
       "      <td>-0.001807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-26</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>92.90</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-29</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>93.52</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.012401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-30</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>92.63</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.009517</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-12-31</th>\n",
       "      <td>12490</td>\n",
       "      <td>IBM</td>\n",
       "      <td>INTERNATIONAL BUSINESS MACHS COR</td>\n",
       "      <td>20990</td>\n",
       "      <td>92.68</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            PERMNO TICKER                            COMNAM  PERMCO    PRC  \\\n",
       "date                                                                         \n",
       "2003-12-24   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  92.27   \n",
       "2003-12-26   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  92.90   \n",
       "2003-12-29   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  93.52   \n",
       "2003-12-30   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  92.63   \n",
       "2003-12-31   12490    IBM  INTERNATIONAL BUSINESS MACHS COR   20990  92.68   \n",
       "\n",
       "                 RET  CFACPR      RETX    sprtrn  \n",
       "date                                              \n",
       "2003-12-24 -0.005604       1 -0.005604 -0.001807  \n",
       "2003-12-26  0.006828       1  0.006828  0.001691  \n",
       "2003-12-29  0.006674       1  0.006674  0.012401  \n",
       "2003-12-30 -0.009517       1 -0.009517  0.000144  \n",
       "2003-12-31  0.000540       1  0.000540  0.002055  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc = np.abs(ibm.PRC.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.07"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prc.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prc.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ibm.sprtrn.values\n",
    "#ret = ibm.RETX.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#begVals = array([mu, w, a, b])\n",
    "r = 100 * ret\n",
    "sigma = np.ones_like(r) * r.var()\n",
    "args = (r, sigma)\n",
    "\n",
    "begVals = array([0.0, 10**-6, .01, .9])\n",
    "finfo = np.finfo(np.float64)\n",
    "bounds = [(-10 , 10), (finfo.eps, 2 * r.var()), (0.0, 1.0), (0.0, 1.0)]\n",
    "\n",
    "#estimates = fmin_slsqp(garch_likelihood, begVals, f_ieqcons=garch_constraints, bounds=bounds, args=args)\n",
    "#bob = minimize(fun=garch_likelihood, x0=begVals, args=(r,s), method='SLSQP', bounds=bounds, constraints=garch_constraints)\n",
    "bob = minimize(fun=garch_likelihood, x0=begVals, args=args, method='L-BFGS-B', bounds=bounds) #, constraints=garch_constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 2081.4537306219727\n",
       " hess_inv: <4x4 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([0.0005457 , 0.00391083, 0.00336513, 0.00545697])\n",
       "  message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
       "     nfev: 320\n",
       "      nit: 33\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.02738401, 0.04148747, 0.07527011, 0.90160256])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated mean return is:  0.02738401\n",
      "The estimated omega value is:  0.04148747\n",
      "The estimated alpha value is:  0.07527011\n",
      "The estimated beta values is:  0.90160256\n"
     ]
    }
   ],
   "source": [
    "res = bob['x']\n",
    "\n",
    "print(f\"The estimated mean return is: {res[0] : 0.8f}\")\n",
    "print(f\"The estimated omega value is: {res[1] : 0.8f}\")\n",
    "print(f\"The estimated alpha value is: {res[2] : 0.8f}\")\n",
    "print(f\"The estimated beta values is: {res[3] : 0.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023127329801457486"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - res[2] - res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.261601831419906"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(res[1] / (1.0 - res[2] - res[3])) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.22957178731841"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(r, ddof=1) * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GJR-GARCH(1,1,1) Model Estimation via MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
